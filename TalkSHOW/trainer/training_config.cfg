[Input Output]
checkpoint_dir = ./training
expression_basis_fname = ./training_data/init_expression_basis.npy
template_fname = ./template/FLAME_sample.ply
deepspeech_graph_fname = ./ds_graph/output_graph.pb
face_or_body = body
verts_mmaps_path = ./training_data/data_verts.npy
raw_audio_path = ./training_data/raw_audio_fixed.pkl
processed_audio_path = ./training_data/processed_audio_deepspeech.pkl
templates_path = ./training_data/templates.pkl
data2array_verts_path = ./training_data/subj_seq_to_idx.pkl

[Audio Parameters]
audio_feature_type = deepspeech
num_audio_features = 29
audio_window_size = 16
audio_window_stride = 1
condition_speech_features = True
speech_encoder_size_factor = 1.0

[Model Parameters]
num_vertices = 10475
expression_dim = 50
init_expression = False
num_consecutive_frames = 30
absolute_reconstruction_loss = False
velocity_weight = 10.0
acceleration_weight = 0.0
verts_regularizer_weight = 0.0

[Data Setup]
subject_for_training = speeker_oliver
sequence_for_training = 0-00'00'05-00'00'10 1-00'00'32-00'00'37 2-00'01'05-00'01'10
subject_for_validation = speeker_oliver
sequence_for_validation = 2-00'01'05-00'01'10
subject_for_testing = speeker_oliver
sequence_for_testing = 2-00'01'05-00'01'10

[Learning Parameters]
batch_size = 64
learning_rate = 1e-4
decay_rate = 1.0
epoch_num = 1000
adam_beta1_value = 0.9

[Visualization Parameters]
num_render_sequences = 3

